{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"working_with_hdfs.ipynb","provenance":[],"collapsed_sections":["CiXAtQEjLdxf","OwI3SjRftBqM","2Pg-da4VH6se","P8mkAqat0nDy"],"authorship_tag":"ABX9TyOmv/GvpJSY7bBD/dso8plp"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CiXAtQEjLdxf"},"source":["#outline"]},{"cell_type":"markdown","metadata":{"id":"1P4IgjIYqak9"},"source":["\n","okay so after doing my simple map reduce task, I thought next would be good to deal a little bit with moving/working with files in HDFS.\n","\n","of course, the hadoop cluster and data nodes are all running in containers.\n","(though on a single machine). So far I have been copying small files into hadoop container and then from the local FS to the HDFS.\n","\n","Now I need to connect the container FS and the local machine FS through the mounting of some volume, and then also think about how to move them into HDFS.\n","One more thing is to properly set the location of the datanodes on disk, so we have some control on how they take up space in the hard drives.\n","\n","and finally, one thing that I really wanted to find out, is how the file meta data ( especially in windows files, for documents, images, videos, etc, (which are aparently called extended properties) are handled and how can they be moved to the hdfs.\n","\n","okay, so with this the rough outline of what I had in mind for the work, lets see what we can actually do.\n","\n","so although the questions on setup of HDFS mount places seems very important, I actually started with the last question and have not touched the other ones much, so I will leave a place holder for them for now.\n"]},{"cell_type":"markdown","metadata":{"id":"OwI3SjRftBqM"},"source":["#connect Hadoop cluster containers with local drives:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oE9uBtU4umya"},"source":["So again this has two directions which both deal with the set up of conatiner images.  how to connect the  hdfsd cluster namenode with the local machine and how to connect the datanodes on local machine. (basically for source and destination of the data on machine)\n"]},{"cell_type":"code","metadata":{"id":"OCruE1d7oK6Z"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"16BgBkSZxHgt"},"source":["# Move/Transfer and Process of data from local FS to the HDFS:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gju2N2jgylFH"},"source":["Assuming that I have  some (big) files on the local FS of the  HDFS namenode, (i.e main node), the question is how to copy or move, or attach them to the hdfs that is most efficient.\n","\n","\n","Also,  let's say we have added the data files to the HDFS, how can we access their meta data, e.g. date-modified, adress on local disk, format, etc.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2Pg-da4VH6se"},"source":["## What is the best way of loading files from local to hdfs\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ztOQS50HIZPd"},"source":["Afterall, I had seen a few commands like put and copyFromLocal etc. \n","Does any of them provide an advantage for large amount of data. \n","\n","Especially is there someway not to actually do much copying?!\n","\n","I was thinking also idewally if we could attach the data to the HDFS, where the files would not be coppied again, but just manged by hdfs that could be good.\n","\n","I did a bit of search, this one looks interesting, though not quite what I am looking for.\n","\n","https://stackoverflow.com/questions/39193790/what-is-the-best-way-of-loading-huge-size-files-from-local-to-hdfs"]},{"cell_type":"markdown","metadata":{"id":"TuO3VS4DzEu2"},"source":["## file metadata, properties, or extended atributes:\n"]},{"cell_type":"markdown","metadata":{"id":"vzEXgrfmzZ09"},"source":["okay so I notcied before that in wondows, you have a lof different metadata, such as date_created, date_modified, format, tag, description, and so on, exist for each file which I wanted to know how they are manged. I thought a similar thing could be in place for linux files, but any of them is okay to start.\n","\n","I thought that those metadata should be kept attached to the files,  so they are accessible by other systems as well, and turns out it is mostly correct.\n","Now I started with this question, on how these metadat are manged anyways!?\n"]},{"cell_type":"markdown","metadata":{"id":"P8mkAqat0nDy"},"source":["### Where does windows store file metadata?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"D8vZsy4C1GsK"},"source":["Looks like someone aasked these exact questioin in [Stackoverflow](\n","https://stackoverflow.com/questions/6080319/where-does-windows-explorer-store-file-meta-data).\n","\n","but the answers were not quite usefull (or at my level of undrstanding).\n","So I got to know that these metadata, are called  **properties** or **extended atributes** and they can be stored in differernt places, but mostly with the files, and looks like there are some APIs in winbows to work with them, but that is all I could get.\n","\n","I also found these materials somewhat relevant:\n","\n","https://docs.microsoft.com/en-us/windows/win32/api/shobjidl_core/nn-shobjidl_core-ishellitem2?redirectedfrom=MSDN\n","( well this seems to show the interface for working with file atributes, but it made me more confused honestly, not sure what is this framework)\n","\n","https://stackoverflow.com/questions/56827719/how-to-copy-file-metadata-on-linux-and-windows-from-and-to-any-filesystem-that-i\n","another question on this file metadata, but not that much of usefull\n","\n","wiki page A quick guide on the extended file attributes \n","https://en.wikipedia.org/wiki/Extended_file_attributes\n","\n","\n","okay so far not much helpfull or straight forward. I said, forget about the windows now, let's see how Linux deal with extended file attributes, and more importantly how hadoop deals with them.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Xmsf9ks-4j4f"},"source":["### How to access the file extended attributes in Linux "]},{"cell_type":"markdown","metadata":{"id":"8a3t9a5L5god"},"source":["So I guess before actually attending to this question, I was after this same question only on HDFS.\n","I thought maybe there is some easy command to access it afterall?!\n","I was also after questions like this : **how to transfer file extended metadata to hdfs**\n","\n","The answers I found was in this line:\n","\n","[Apache Hadoop 3.3.0 â€“ Extended Attributes in HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html)\n","\n","and also these two:\n","\n","[How to get files metadata, when retrieving data from HDFS?](https://stackoverflow.com/questions/61317600/how-to-get-files-metadata-when-retrieving-data-from-hdfs)\n","\n","(well this solution seems to be related to  Spark and Scala, but the question is right to the point)\n","(maaybe I just better to go take a look at *italicized text*\n","\n","[Getting File Metadata Using \"hdfs fsck\"\n","](https://www.youtube.com/watch?v=s577NlJ7fi4&ab_channel=itversity)"]}]}